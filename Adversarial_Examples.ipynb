{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\E}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# My standard magic !  You will see this in almost all my notebooks.\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "import cnn_helper\n",
    "%aimport cnn_helper\n",
    "cnnh = cnn_helper.CNN_Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adversarial examples\n",
    "\n",
    "We introducted Gradient Ascent in our [module on interpretation](Interpretation_of_DL_Gradient_Ascent.ipynb)\n",
    "- We find the input $\\x^*$\n",
    "- That maximizes the value of a particular neuron $\\y_{\\llp, \\idxspatial, k}$\n",
    "\n",
    "$$\n",
    "\\x^* = \\argmax{ \\x = \\y_{(0)} } \\y_{\\llp, \\idxspatial, k}\n",
    "$$\n",
    "\n",
    "In that module, we used the technique to find the input value $\\x$ that \"maximally excited\"\n",
    " $\\y_{\\llp, \\idxspatial, k}$.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this module, the neuron we will maximally excite will be in the head layer $L$.\n",
    "\n",
    "If layer $L$ is a classifier for a task with classes in set $C$\n",
    "- Then $\\y_{(L)}$ is a vector of length $C$\n",
    "- Where $\\y_{(L),j}$ corresponds to the predicted probability that the correct class is $C_j$\n",
    "    - denoting the $j^{th}$ class as $C_j$\n",
    "$$    \n",
    "    \\x^* = \\argmax{ \\x = \\y_{(0)} } \\y_{(L),j} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <center><strong>Layers</strong></center>\n",
    "    <br>\n",
    "<img src=\"images/NN_Layers.png\">\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That is: we will solve for the $\\x^*$\n",
    "- That is the example that looks like $C_j$ \n",
    "- More than *any* value in the input domain\n",
    "- The \"perfect $C_j$\"\n",
    "\n",
    "If $C$ were the class of animals and the domain of $\\x$ were images\n",
    "- This would be like finding \"the perfect dog\" image\n",
    "- At least according to the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pretty innocuous.\n",
    "\n",
    "But what if we *constrained the optimization*\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\x^* = \\argmax{ \\x = \\y_{(0)} } \\y_{(L),j} \\\\\n",
    "\\text{subject to} \\\\\n",
    "\\text{looks like}(\\x, \\x')\n",
    "\\end{array}\n",
    "$$\n",
    "where \n",
    "- $\\text{looks like}(\\x, \\x')$\n",
    "- Is a \"closeness\" metric that increases when chosen $\\x$ is most similar to a specific $\\x'$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And what if $\\x'$ were from some class $C_{j'} \\ne C_j$ ?\n",
    "\n",
    "That is\n",
    "- We find the $\\x^*$\n",
    "- That gets classified with high confidence as being $C_j$\n",
    "- But it actually in a different class $C_{j'}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The $\\x^*$ obtained is called an *Adversarial Example*\n",
    "- One specifically constructed to \"fool\" the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Adversarial examples in action:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <center><strong>What class is this ?</strong></center>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/cat7_classified.png\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What about this ?\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <center><strong>What class is this ?</strong></center>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/cat7_as_class_859_classified.png\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "It's almost certainly a toaster !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That was fun, but is it innocuous ?\n",
    "\n",
    "How about the following picture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr><center><strong>Adversarial Stop Sign</strong></center></tr>\n",
    "<tr>\n",
    "    <td><img src=\"images/love_stops_hate_stop.jpg\"></td>\n",
    "    <td><img src=\"images/grafitti_stop.jpg\"></td>    \n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <td colspan=2><center><strong>\"Speed Limit 45 mph\"</strong></center></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Attribution: [Robust Physical-World Attacks on Deep Learning Models](https://arxiv.org/abs/1707.08945)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Remember, the Neural Network has previously been reported to have super-human accuracy !\n",
    "\n",
    "What's going on here ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The problem is that we don't actually *know* how the Neural Network recognizes a toaster.\n",
    "\n",
    "The optimizer has learned to change exactly those input pixels\n",
    "- That the Neural Network uses to classify a toaster\n",
    "- And, with enough additional constraints\n",
    "- The changes are not detectable by the human eye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is a visualization of the pixels that were changed\n",
    "- In order to reclassify the cat (left image)\n",
    "- As a toaster (right image)\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <center><strong>Adversarial Cat to Toaster</strong></center>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/cat7_classified.png\" width=1000></td> \n",
    "        <td><img src=\"images/cat7_as_class_859_diff.png\" width=1000></td>\n",
    "        <td><img src=\"images/cat7_as_class_859_classified.png\" width=1000></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It should be clear that Adversarial Examples violate the Fundamental Assumption of Machine Learning\n",
    "- A test example\n",
    "- Comes from the same distribution as the Training examples\n",
    "\n",
    "We are able to fool the Neural Network by asking it to solve a problem for which it wasn't trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This highlights an important issue\n",
    "- Since we don't know how Neural Networks work\n",
    "- How can we confidently deploy them in the physical world ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Adversarial Attacks are able to fool an otherwise high quality Neural Network\n",
    "- Without corrupting any training examples\n",
    "- Without altering the weights of the Neural Network\n",
    "- Without giving the Attacker access to any information about the Neural Network\n",
    "\n",
    "So the attack can occur even on a Neural Network that appears as a \"black box\" to the attacker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Adversarial Examples are inputs that are crafted for the purpose of \"fooling\" a Neural Network.\n",
    "\n",
    "The attacks use the same techniques that are otherwise used to correctly train a network.\n",
    "\n",
    "This is a significant issue that must be addressed before Neural Networks can be entrusted\n",
    "with tasks that have real-world consequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adversarial Reprogramming\n",
    "\n",
    "We can extend the Gradient Ascent method to perform even bigger tricks:\n",
    "- Getting a Classifier for Task 1 to do something completely different !\n",
    "\n",
    "Something to consider\n",
    "- Does your smart phone run Neural Network based apps ? (e.g., Snapchat filters)\n",
    "- Can we trick this app into doing *something else* ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is called *Adversarial Reprogramming*.\n",
    "\n",
    "We will sketch how a super-human quality ImageNet Classifier can be tricked.\n",
    "- Source Task: Classify images from among 1000 classes\n",
    "- Target Task: Count squares in an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Target task might sound simple, but observe\n",
    "- That the \"square\" is not one of the 1000 ImageNet targets\n",
    "- ImageNet has not been trained on numbers, much less to count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We refer to ImageNet Classification as the Source task.\n",
    "\n",
    "Our goal is to get the Classifier to solve the Target task: Counting Squares.\n",
    "\n",
    "The first issue to address:\n",
    "- the $(\\x^\\ip, \\y^\\ip)$ pairs of the Source task come from a different domain than that of the Target task\n",
    "\n",
    "$$\n",
    "\\begin{array}[lll]\\\\\n",
    "\\X_\\text{source}, \\y_\\text{source}: & \\text{examples for Source task} \\\\\n",
    "\\X_\\text{target}, \\y_\\text{target}: &  \\text{examples for Target task} \\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can solve this by creating a simple function $h_f$ to map\n",
    "- $\\x_\\text{target}$, a feature vector in the Target task's domain.\n",
    "- To $ \\tilde\\x_\\text{source}$, a feature vector in the Source task's domain.\n",
    "\n",
    "This ensures that the input to the Source task is of the right \"type\".\n",
    "\n",
    "Here's a picture of mapping \"Squares\" to an \"Image\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "<tr><center><strong>Adversarial Reprogramming</strong></center></tr>\n",
    "<tr>\n",
    "    <td><img src=\"images/Adv_reprog_hf.png\"></td>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$h_f$ simply embeds the Target input into an image (the domain of the Source task).\n",
    "\n",
    "Similarly, we create a function $h_g$ to map the Target label to a Source Label.\n",
    "\n",
    "This will ensure that the output of the Source task is of the right type.\n",
    "\n",
    "- Here's a mapping from Counts to Image Labels.  \n",
    "- The inverse of this function maps Image Labels to Counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| Count  | Label|\n",
    "| --- | :- | \n",
    "| 1 | **Tench** |\n",
    "| 2 | **Goldfish**|\n",
    "| 3 | **White shark** |\n",
    "| 4 | **Tiger shark** |\n",
    "| 5 | **Hammerhead** |\n",
    "| 6 | **Electric ray** |\n",
    "| 7 | **Stringray** |\n",
    "| 8 | **Cock** |\n",
    "| 9 | **Hen** |\n",
    "| 10 | **Ostrich** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here's the overall picture of adapting an ImageNet Classifier to Count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "<tr><center><strong>Adversarial Reprogramming: Architecture</strong></center></tr>\n",
    "<tr>\n",
    "    <td><img src=\"images/Adv_reprog.png\"></td>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, the \n",
    "Loss function to minimize\n",
    "\n",
    "$$\n",
    "\\W = \\argmin{\\W}{ - \\log( \\pr{h_g( \\y_\\text{target} ) \\; | \\;\\tilde{\\x}_\\text{source} }) + \\lambda || \\W ||^2 }\n",
    "$$\n",
    "\n",
    "where\n",
    "$$\n",
    "\\begin{array}[lll]\\\\\n",
    "\\tilde{\\x}_\\text{source} & = & h_f( \\W, \\x_\\text{target}) \\\\\n",
    "h_f: & &\\y_\\text{target} \\mapsto \\y_\\text{source} & \\text{map source X to target X} \\\\\n",
    "h_g: & &\\y_\\text{target} \\mapsto \\y_\\text{source} & \\text{map source label y to target label} \\\\\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Let's break this seemingly complicated formula down into simple pieces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given an input example $(\\x_\\text{target}, \\y_\\text{target})$ for the Target task\n",
    "- Translate feature vector $\\x_\\text{target}$ into a valid input for the Source Task\n",
    "- Using $h_f$\n",
    "$$\n",
    "\\begin{array}[lll]\\\\\n",
    "\\tilde{\\x}_\\text{source} & = & h_f( \\W, \\x_\\text{target}) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "- Which is parameterized by $\\W$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We also need to translate $\\y_\\text{target}$ to a valid label for the Source Task\n",
    "$$h_g( \\y_\\text{target} )$$\n",
    "Is the Source label corresponding to the Target label $\\y_\\text{target}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The objective function being minimized\n",
    "$$\n",
    "\\W = \\argmin{\\W}{ - \\log( \\pr{h_g( \\y_\\text{target} ) \\; | \\;\\tilde{\\x}_\\text{source} }) + \\lambda || \\W ||^2 }\n",
    "$$\n",
    "- Is our old friend: Cross Entropy Loss\n",
    "- With a regularization penalty $\\lambda || \\W ||^2$\n",
    "- Trying to get Source Task Classifier to predict $h_g( \\y_\\text{target} )$\n",
    "    - Given input $\\tilde{\\x}_\\text{source}  =  h_f( \\W, \\x_\\text{target})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  \n",
    "That is: we are trying to\n",
    "- Maximize the likelihood that the Source classifier creates the encoding for the correct Target label\n",
    "- Subject to constraining the weights $\\W$ (the \"frame\" into which the Target input is placed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How does this magic occur ?\n",
    "\n",
    "By training !\n",
    "- We find the $\\W$\n",
    "- Used by $h_f$\n",
    "- Such that the objective is met\n",
    "\n",
    "Nothing new !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Misaligned objectives\n",
    "\n",
    "*AI Security* is the area of research concerned  with the potential for humans to **cause harm to AI**\n",
    "- Adversarial examples\n",
    "    \n",
    "*AI Safety* is the analogous area concerned with the potential for AI to **cause harm to humans**\n",
    "\n",
    "Safety problems can arise when the Loss Function and human objectives diverge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Consider the difference between\n",
    "- \"Maximize profit\"\n",
    "- \"Maximize profit subject to legal and ethical constraints\"\n",
    "\n",
    "We (hopefully) don't have to state the additional constraints to a human -- we take it for granted.\n",
    "\n",
    "Not so with a machine that has not been trained with examples expressing the additional objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This leads to a phenomenon known as *reward hacking*\n",
    "- The training algorithm decreases the Loss Function\n",
    "- Even to the point of what a human would consider \"cheating\"\n",
    "    - Achieving infinite score on a video game by discovering and exploiting a programming error\n",
    "- But it is not cheating ! Just an optimizer doing its job.        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here's an amusing example\n",
    "- A spider-like robot \"learns\" to walk (Loss function)\n",
    "- Human modifies Loss Function\n",
    "- Adding the constraint \"minimize foot contact with ground\"\n",
    "- In an attempt to get the robot to learn to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr><center><strong>Walking without feet touching the ground</strong></center></tr>\n",
    "<tr>\n",
    "    <td><img src=\"images/walk_on_elbows.png\"></td>  \n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "Attribution: [The Surprising Creativity of Digital Evolution: ...](https://arxiv.org/pdf/1803.03453v1.pdf)\n",
    "\n",
    "The spider learns to walk on its elbows !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Adversarial Reprogramming is a technique that can abuse an otherwise useful Deep Learning system.\n",
    "\n",
    "It involves nothing more than an application of techniques that we have already learned\n",
    "\n",
    "We also briefly mentioned the topic of AI Safety: how Deep Learning systems may come to cause harm.\n",
    "\n",
    "We have learned powerful tools. It's important to be aware that they can be used for harm as well as good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
