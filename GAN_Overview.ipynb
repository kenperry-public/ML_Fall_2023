{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\E}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb\n",
    "%run beautify_plots.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generative Adversarial Networks: creating realistic fake examples\n",
    "\n",
    "**Aside**\n",
    "\n",
    "The [GAN](https://arxiv.org/pdf/1406.2661.pdf) was invented by Ian Goodfellow in one night, following a party at a [bar](https://www.technologyreview.com/2018/02/21/145289/the-ganfather-the-man-whos-given-machines-the-gift-of-imagination/) !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our goal is to generate new *synthetic* examples.\n",
    "\n",
    "Let\n",
    "- $\\x$ denote a *real* example\n",
    "    - vector of length $n$\n",
    "- $\\pdata$ be the distribution of real examples\n",
    "   - $\\x \\in \\pdata$\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will create a Neural Network called the *Generator*\n",
    "\n",
    "Generator $G_{\\Theta_G}$ (parameterized by $\\Theta_G$) will\n",
    "- take a vector $\\z$ of random numbers from distribution $p_\\z$ as input\n",
    "- and output $\\hat{\\x}$ \n",
    "- a *synthetic/fake* example\n",
    "    - vector of length $n$\n",
    "\n",
    "Let\n",
    "- $\\pmodel$ be the distribution of fake examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>GAN Generator</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/GAN_generator.png\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The Generator will be paired with another Neural Network called the *Discriminator*.\n",
    "\n",
    "The Discriminator $D_{\\Theta_D}$ (parameterized by $\\Theta_D$) is a binary Classifier\n",
    "- takes a vector $\\tilde{\\x} \\in \\pdata \\cup \\pmodel$\n",
    "\n",
    "**Goal of Discriminator**\n",
    "$$\n",
    "\\begin{array} \\\\\n",
    "D( \\tilde{\\x} ) & = & \\text{Real} & \\text{ for } \\tilde{\\x} \\in p_\\text{data} \\\\\n",
    "D (\\tilde{\\x} ) & = &\\text{Fake}  &\\text{ for } \\tilde{\\x} \\in p_\\text{model}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "That is\n",
    "- the Discriminator tries to distinguish between Real and Fake examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>GAN Discriminator</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/GAN_discriminator.png\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In contrast, the goal of the Generator\n",
    "\n",
    "**Goal of Generator**\n",
    "$$\n",
    "\\begin{array} \\\\\n",
    "D (\\hat{\\x} ) & = & \\text{Real} & \\text{ for } \\hat{\\x} = G_{\\Theta_G}(\\z)  \\in p_\\text{model}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "That is\n",
    "- the Generator tries to create fake examples that can fool the Discriminator into classifying as Real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How is this possible ?\n",
    "\n",
    "We describe a training process (that updates $\\Theta_G$ and $\\Theta_D$)\n",
    "- That follows an *iterative* game\n",
    "- Train the Discriminator to distinguish between \n",
    "    - Real examples\n",
    "    - and the Fake examples produced by the Generator on the prior iteration\n",
    "- Train the Generator to produce examples better able to fool the updated Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sounds reasonable, but how do we get the Generator to improve it's fakes ?\n",
    "\n",
    "We will define loss functions \n",
    "- $\\loss_G$ for the Generator\n",
    "- $\\loss_D$ for the Discriminator\n",
    "\n",
    "Then we can improve the Generator (parameterized by $\\Theta_G$) by Gradient Descent\n",
    "- updating $\\Theta_G$ by $- \\frac{\\partial\\loss_G}{\\partial {\\Theta_G}}$\n",
    "\n",
    "That is\n",
    "- The Discriminator will indirectly give \"hints\" to the Generator as to why a fake example failed to fool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>GAN Generator training</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/GAN_generator_train.png\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>GAN Discriminator training</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/GAN_discriminator_train.png\"</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "After enough rounds of the \"game\" we hope that the Generator and Discriminator battle to a stand-off\n",
    "- the Generator produces realistic fakes\n",
    "- the Discriminator has only a $50 \\%$ chance of correctly labeling a fake as Fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Notation**\n",
    "\n",
    "text | meaning                       \n",
    ":----|:---|\n",
    "<img width=100 /> | <img width=300 /> \n",
    "$p_\\text{data}$ | Distribution of real data \n",
    "$\\x \\in p_\\text{data}$  | Real sample \n",
    "$p_\\text{model}$ | Distribution of fake data \n",
    "$\\hat{\\x}$ | Fake sample\n",
    "           | $\\hat{\\x} \\not\\in p_\\text{data}$ \n",
    "           | $\\text{shape}(\\hat{\\x}) = \\text{shape} ( \\x ) $\n",
    "           $\\tilde{\\x}$ | Sample (real of fake)\n",
    "             | $\\text{shape} ( \\tilde{\\x} ) =\\text{shape}(\\x)$\n",
    "$D_{\\Theta_D}$ | Discriminator NN, parameterized by $\\Theta_D$ \n",
    "               | Binary classifier:  $\\tilde{\\x} \\mapsto \\{ \\text{Real}, \\text{Fake} \\} $\n",
    "               | $D_{\\Theta_D}(\\tilde{x}) \\in \\{ \\text{Real}, \\text{Fake} \\} \\text{ for } \\text{shape}(\\tilde{\\x}) = \\text{shape}(\\x)$ \n",
    "$\\z$ | vector or randoms with distribution $p_\\z$\n",
    "$G_{\\Theta_G}$  | Generator NN, parameterized by $\\Theta_G$  \n",
    "                | $\\z \\mapsto \\hat{\\x}$\n",
    "                | $\\text{shape}( G(\\z) ) = \\text{shape}(\\x)$\n",
    "                | $G(\\z) \\in p_\\text{model}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Loss functions\n",
    "\n",
    "The goal of the generator can be stated as\n",
    "- Creating $\\pmodel$ such that\n",
    "- $\\pmodel \\approx \\pdata$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " \n",
    "There are a number of ways to measure the dis-similarity of two distributions\n",
    "- KL divergence\n",
    "    - equivalent to Maximum Likelihood estimation\n",
    "- Jensen Shannon Divergence (JSD)\n",
    "- Earth Mover Distance (Wasserstein GAN)\n",
    "\n",
    "The original paper choose the minimization of the KL divergence, so we illustrate with that measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To be concrete. let the Discriminator uses labels\n",
    "- $1$ for Real\n",
    "- $0$ for Fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "The Discriminator tries to maximize\n",
    "\n",
    "$$\n",
    "- \\loss_D = \n",
    "\\begin{cases} \n",
    "\\log D(\\tilde{\\x}) & \\text{ when } \\tilde{\\x} \\in \\pdata \\\\\n",
    "1 - \\log D(\\tilde{\\x}) & \\text{ when } \\tilde{\\x} \\in \\pmodel \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "That is\n",
    "- Classify real $\\x$ as Real\n",
    "- Classify fake $\\hat{\\x}$ as Fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The per-example Loss for the Generator is \n",
    "$$\\loss_G = 1 - \\log D(G(\\z))$$\n",
    "\n",
    "which is achieved when the fake example \n",
    "$$D(G(\\z)) = 1$$\n",
    "\n",
    "That is\n",
    "- the Discriminator mis-classifies the fake example as Real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So the iterative game seeks to solve a minimax problem\n",
    "\n",
    "$$\n",
    "\\min{G}\\max{D} \\left( { \\mathbb{E}_{\\x \\in p_\\text{data}} \\log D(\\x) + \\mathbb{E}_{\\z \\in p_z} ( 1 - \\log D(G(\\z))} \\right)\n",
    "$$\n",
    "- $D$ tries to \n",
    "    - make $D(\\x)$ big: correctly classify (with high probability) real $\\x$\n",
    "    - and $D(G(\\z))$ small: correctly classify (with low probability) fake $G(\\z))$\n",
    "- $G$ tries to\n",
    "    - make $D(G(\\z))$ high: fool $D$ into a high probability for a fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that the Generator improves \n",
    "- by updating $\\Theta_G$\n",
    "- so as to increase $D(G(\\z))$\n",
    "    - the mis-classification of the fake as Real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Training\n",
    "\n",
    "We will train Generator $G_{\\Theta_G}$ Discriminator $D_{\\Theta_D}$ by turns\n",
    "- creating sequence of updated parameters\n",
    "    - $\\Theta_{G, (1)} \\ldots \\Theta_{G,(T)}$\n",
    "    - $\\Theta_{D, (1)} \\ldots \\Theta_{D,(T)}$\n",
    "- Trained *competitively*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Competitive training**\n",
    "\n",
    "Iteration $\\tt$\n",
    "\n",
    "- Train $D_{\\Theta_{D, (\\tt-1)}}$ on samples\n",
    "    - $\\tilde{\\x} \\in p_\\text{data} \\cup p_{\\text{model}, (\\tt-1)}$\n",
    "        - where $G_{\\Theta_{G, (\\tt-1)}} ( \\z) \\in p_{\\text{model}, (\\tt-1)}$\n",
    "    - Update $\\Theta_{D, (\\tt-1)}$ to $\\Theta_{D, \\tp}$ via gradient $\\frac{\\partial \\loss_D}{\\partial \\Theta_{D,(\\tt-1)}}$\n",
    "        - $D$ is a maximizer of $\\int_{\\x \\in p_\\text{data}} \\log D(\\x) + \\int_{\\z \\in p_\\z} \\log ( \\, 1 - D(G(\\z)) \\, )$\n",
    "- Train $G_{\\Theta_{G, (\\tt-1)}}$ on random samples $\\z$\n",
    "    - Create samples $\\hat{\\x}_\\tp \\in G_{\\Theta_{G, (\\tt-1)}}(\\z)  \\in p_\\text{model}$\n",
    "    - Have Discriminator $D_{\\Theta_{D, \\tp}}$ evaluate $D_{\\Theta_{D,\\tp}} ( \\hat{\\x}_\\tp )$\n",
    "    - Update $\\Theta_{G, (\\tt-1)}$ to $\\Theta_{G, \\tp}$ via gradient $\\frac{\\partial \\loss_G}{\\partial \\Theta_{G,(\\tt-1)}}$\n",
    "        - $G$ is a minimizer of $\\int_{\\z \\in p_\\z} \\log ( \\, 1 - D(G(\\z)) \\, )$\n",
    "            - i.e., want $D(G(\\z))$ to be high\n",
    "    - May update $G$ multiple times per update of $D$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Training code for a simple GAN**\n",
    "\n",
    "[Here](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/dcgan_overriding_train_step.ipynb#scrollTo=AOO8AqLy86jb)\n",
    "       is the code for the training step of a simple GAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Code\n",
    "\n",
    "- [GAN on Colab](https://keras.io/examples/generative/dcgan_overriding_train_step/)\n",
    "- [Wasserstein GAN with Gradient Penalty](https://keras.io/examples/generative/wgan_gp/#create-the-wgangp-model)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
