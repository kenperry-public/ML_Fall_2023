{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( #1 \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% VAE\n",
       "\\def\\prs#1#2{\\mathcal{p}_{#2}(#1)}\n",
       "\\def\\qr#1{\\mathcal{q}(#1)}\n",
       "\\def\\qrs#1#2{\\mathcal{q}_{#2}(#1)}\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A  Universal API:  Language Modeling to solve many tasks\n",
    "\n",
    "The Language Modeling objective seems simple, but appearances are deceiving.\n",
    "\n",
    "We have shown that a Language Model can be adapted for new Target tasks\n",
    "- via the Unsupervised Pre-Training + Supervised Fine-Tuning paradigm.\n",
    "  \n",
    "There is, perhaps, an alternative way to adapt to a new Target task\n",
    "- turn each task *directly* into an instance of the Language Modeling objective.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider a new Target task: Entailment\n",
    "- Input is a *pair* of text sequences $[ \\text{Premise}, \\text{Hypothesis} ]$\n",
    "- Binary classification: Does the Hypothesis Logically follow from the Premise ?\n",
    "\n",
    "          Premise: The students are attending a lecture on Machine Learning\n",
    "          Hypothesis: The students are sitting in a class room\n",
    "          Label: Entails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suppose we construct a sequence for the Language Model to extend\n",
    "- consisting of the Premise, Hypothesis, and the string \"Label:\"\n",
    "\n",
    "We call this sequence the *prompt* or the *context*\n",
    "\n",
    "      Premise: The students are attending a lecture on Machine Learning\n",
    "      Hypothesis: The students are sitting in a class room\n",
    "      Label: \n",
    "\n",
    "We would hope that the Language Model extends the prompt by creating tokens that are the correct response\n",
    "for the Target task\n",
    "\n",
    "    Entail\n",
    "since the Hypothesis logically follows from the Premise (other possible response: `Not Entail`)\n",
    "\n",
    "We have turned Entailment into an instance of Language Modeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As another example: consider the  Target task: Multiple Choice Question answering\n",
    "- Input is\n",
    "    - Context: a sentence or paragraph stating facts\n",
    "    - Question\n",
    "    - Answers: a set of possible answer sentences\n",
    "    \n",
    "We construct a prompt of the form\n",
    "    \n",
    "    \n",
    "    Context: It is December of 2022.  Prof. Perry is teaching the second half of the Machine Learning Course.\n",
    "    Question: Where are the students ?\n",
    "    Answer 1: The beach\n",
    "    Answer 2: In a classroom in Brooklyn\n",
    "    Answer 3: Dreaming of being elsewhere.\n",
    "    \n",
    "    Label: \n",
    "    \n",
    "and hope that the Language Model extends the prompt string with one of\n",
    "\n",
    "    { Answer 1, Answer 2, Answer 3 }\n",
    "\n",
    "- hopefully with probability near 100% for Answer 2 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Power of text as the Universal API\n",
    "\n",
    "The Universal API turns each task into an instance of the  Language Modeling task.\n",
    "\n",
    "What this means is that\n",
    "- we might not need *task-specific* models\n",
    "- just transform every task into instance of the \"predict the next\" word task\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "After converting our Source task into a LLM task\n",
    "- we would ordinarily use Supervised Fine-Tuning\n",
    "- on a dataset of (transformed) examples from the Target Task\n",
    "- to Fine-Tune the LLM for the Target task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The transformed Target task training dataset would consist of examples like\n",
    "\n",
    "$$\\langle \\x^\\ip, \\y^\\ip \\rangle = \\langle \\text{prompt}, \\text{response} \\rangle$$\n",
    "\n",
    "That is\n",
    "- the \"features\" turned into text (\"prompt\")\n",
    "- the label (\"response\") is the continuation of the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In-Context Learning\n",
    "\n",
    "The Universal API also opens up an interesting possibility\n",
    "- Can we use a Large Language Model\n",
    "- To solve a new Target task\n",
    "- *without* further training (i.e., Fine-Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On a pure syntax level, this is feasible\n",
    "- all problems are instances of \"predict the next\"\n",
    "- perhaps the LLM's text completion power *also* captures domain-specific knowledge\n",
    "    - the completion is related to the domain-specific words of the prompt\n",
    "    - for example, if the prompt is in French, the completion would be expected to be in French too\n",
    "\n",
    "So the possibility is there.\n",
    "\n",
    "But how does the Source LLM discern what the Target task is ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The idea behind *In-Context Learning* is to\n",
    "- condition the Pre-Trained Language Model (Source LLM)\n",
    "- to complete the prompt of a new Target Task\n",
    "- with the correct response for the Target Task\n",
    "- **without** further training (Fine-Tuning)\n",
    "- merely by providing the examples that demonstrate the behavior of the new Target task\n",
    "- **as parts of the prompt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The examples demonstrating the Target task are called *exemplars*.\n",
    "- each exemplar is provided as a prompt and response pair, as per the Universal API\n",
    "$$\\langle \\x^\\ip, \\y^\\ip \\rangle = \\langle \\text{prompt}, \\text{response} \\rangle$$\n",
    "\n",
    "To predict the response for a new prompt $\\x$\n",
    "- the exemplars are concatenated together (the *Context* $C$)\n",
    "- the Context is a demonstration of the Target Task's relationship between features and label\n",
    "\n",
    "The new prompt $\\x$ is appended to the Context\n",
    "- the Pre-Trained model is expected to complete the prompt\n",
    "- by providing a response specific to the Target task and the prompt $\\x$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, we can describe Translation between languages with the following Context $C$\n",
    "\n",
    "    Translate English to French\n",
    "    \n",
    "    sea otter =>  loutre de mer\n",
    "    \n",
    "    peppermint => menthe poivree\n",
    "    \n",
    "    plush giraffe => girafe peluche\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "   \n",
    "The expectation is that when the user presents the prompt $\\x$\n",
    "\n",
    "         cheese => \n",
    "         \n",
    "the model will respond with the French translation of `cheese`.\n",
    "- the \"next words\" predicted by the Language Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "More formally: \n",
    "- Let $C$ (\"context\") denote the pre-prompt.\n",
    "- Let $\\x$ denote the \"query\" (e.g., `cheese =>`)\n",
    "\n",
    "The unconditional Language Modeling objective\n",
    "$$\n",
    "\\pr{\\y | \\x}\n",
    "$$\n",
    "is to create the sequence $\\y$ that follows the sequence of prompt $\\x$.\n",
    "\n",
    "Here, the pre-prompt conditions the model's objective\n",
    "$$\n",
    "\\pr{\\y | C, \\x }\n",
    "$$\n",
    "to create the sequence $\\y$ that follows from the exemplars $C$ and prompt $\\x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is just a mechanical process\n",
    "- create the sequence $\\dot \\x$\n",
    "- by concatenating some number $k$ of exemplars: $\\langle \\x^{(1)}, \\y^{(1)} \\rangle, \\ldots, \\langle \\x^{(k)}, \\y^{(k)} \\rangle $\n",
    "- and  prompt string $\\x$\n",
    "- delimiting elements by separator characters $\\langle \\text{SEP}_1 \\rangle. \\langle \\text{SEP}_2 \\rangle$\n",
    "\n",
    "$$\n",
    "\\begin{array} \\\\\n",
    "\\dot \\x = \\text{concat} (  & \\x^{(1)}, \\langle \\text{SEP}_1 \\rangle, \\y^{(1)}, \\langle \\text{SEP}_2 \\rangle,  \\\\\n",
    "              &   \\vdots \\\\\n",
    "              &   \\x^{(k)}, \\langle \\text{SEP}_1 \\rangle, \\y^{(k)}, \\langle \\text{SEP}_2 \\rangle, \\\\\n",
    "              &   \\x \\\\\n",
    "              & ) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The LLM then computes\n",
    "$$\n",
    "\\pr{ \\y | \\dot \\x }\n",
    "$$\n",
    "\n",
    "For convenience, we will just write this as the conditional probability\n",
    "$$\n",
    "\\pr{\\y | \\x,  C}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In-Context learning: let's experiment\n",
    "\n",
    "The [HuggingFace platform](https://huggingface.co/) has libraries of pre-trained models for many tasks, including Language models.\n",
    "\n",
    "There is a clean API for using these models in code (I recommend their on-line [course](https://huggingface.co/) if you want to play with it).\n",
    "\n",
    "But they also host many of their models for interactive use.\n",
    "\n",
    "This is valuable not just for the obvious reason of ease of use\n",
    "- some models are too big to load on the machines available to us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For fun, let's try using In-Context learning in order to get a Pre-Trained Language model to\n",
    "classify whether a short movie review is positive or negative.\n",
    "\n",
    "[Movie review sentiment: few shot learning GPT-2](https://huggingface.co/gpt2?text=this+movie+was+great%3A+positive%0A%0A+one+of+the+best+films+of+the+year%3A+positive+%0A%0Ajust+plain+awful%3A+negative+%0A%0AI+would+not+see+this+one+again%3A+negative+%0A%0Athis+movie+was+great%3A+positive+%0A%0Aone+of+the+best+films+of+the+year%3A+positive+%0A%0A+just+plain+awful%3A+negative+%0A%0AI+would+not+see+this+one+again%3A+negative+%0A%0AI+am+disturbed+by+this+film%3A)\n",
    "\n",
    "[Movie review sentiment: few shot learning GPT-J 6B](https://huggingface.co/EleutherAI/gpt-j-6B?text=this+movie+was+great%3A+positive%0A%0A+one+of+the+best+films+of+the+year%3A+positive+%0A%0Ajust+plain+awful%3A+negative+%0A%0AI+would+not+see+this+one+again%3A+negative+%0A%0Athis+movie+was+great%3A+positive+%0A%0Aone+of+the+best+films+of+the+year%3A+positive+%0A%0A+just+plain+awful%3A+negative+%0A%0AI+would+not+see+this+one+again%3A+negative+%0A%0AI+am+disturbed+by+this+film%3A)\n",
    "\n",
    "[Movie review sentiment: few shot learning:gpt-neox-20b](https://huggingface.co/EleutherAI/gpt-neox-20b?text=this+movie+was+great%3A+positive%0A%0A+one+of+the+best+films+of+the+year%3A+positive+%0A%0Ajust+plain+awful%3A+negative+%0A%0AI+would+not+see+this+one+again%3A+negative+%0A%0Athis+movie+was+great%3A+positive+%0A%0Aone+of+the+best+films+of+the+year%3A+positive+%0A%0A+just+plain+awful%3A+negative+%0A%0AI+would+not+see+this+one+again%3A+negative+%0A%0AI+am+disturbed+by+this+film%3A)\n",
    "\n",
    "You can try cutting and pasting the prompt into the hosted inference instance of other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can play with In-Context learning by going to the page of a model and typing into the *Hosted Inference API* text box.\n",
    "\n",
    "But there is also an API that allows you to pass the input (context plus prompt) via a URL.\n",
    "\n",
    "If you click on the `Deploy` button and choose the `Inference API` drop-down\n",
    "- you will see Python code for querying the model programaticly.\n",
    "\n",
    "<img src=\"images/hf_inference_api_code.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Please note\n",
    "- our toy example above used a *single* test example\n",
    "- even if we manage to get a correct prediction on a single example\n",
    "    - we don't have confidence that the new task was successfully learned !\n",
    "    - we really should evaluate success on a larger number of text examples\n",
    "- still: the fact that the exemplars taught the model the correct syntax for an answer is exciting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning to learn\n",
    "\n",
    "Does In-Context learning really work ?\n",
    "\n",
    "We can begin to answer this question by\n",
    "- examining the behavior of a Pre-Trained LLM\n",
    "- on a new task\n",
    "- using $k$ exemplars\n",
    "    - varying $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Depending on $k$, we refer to the behavior of the LLM by slightly different names\n",
    "- **Few shot learning**: $10 \\le k \\le 100$ typically\n",
    "- **One shot learning**: $k = 1$\n",
    "- **Zero shot learning** $k=0$\n",
    "\n",
    "A picture will help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Few/One/Zero shot learning</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/LM_Few_Shot_Training.png\"\" width=80%></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>Picture from: https://arxiv.org/pdf/2005.14165.pdf</center></td>\n",
    "    </tr>   \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Is this even possible ?!   Learning a new task with **zero** exemplars ?\n",
    "\n",
    "Let's look at the reported In-Context Learning results of 3 LLM's of varying size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Few/One/Zero shot learning</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/LM_Few_Shot_Accuracy.png\"\" width=80%></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>Picture from: https://arxiv.org/pdf/2005.14165.pdf</center></td>\n",
    "    </tr>   \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A couple of observations\n",
    "- As the size of the model grows: In-Context Learning behavior improves\n",
    "    - compare the 175 Billion parameter model to the smaller models\n",
    "    - we sometimes refer to this as behavior that \"emerges\" only when a model is sufficiently large\n",
    "- More exemplars (greater $k$) helps\n",
    "    - but not much for the smallest model\n",
    "\n",
    "- Zero shot learning works !\n",
    "    - but this is a behavior that only emerges for very large models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
