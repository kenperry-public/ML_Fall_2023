{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\E}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# My standard magic !  You will see this in almost all my notebooks.\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import neural_net_helper\n",
    "%aimport neural_net_helper\n",
    "\n",
    "nnh = neural_net_helper.NN_Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpreting Representations: Preview\n",
    "\n",
    "We have described an $L$ layer (Sequential) Neural Network as\n",
    "- a sequence of transformations of the input\n",
    "    - each transformation a *layer* $1 \\le \\ll \\le (L-1)$, producing a new *representation* $\\y_\\llp$\n",
    "- that feed the final representation $\\y_{(L-1)}$ to a *head* (classifier, regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <center>Layers</center>\n",
    "    <br>\n",
    "<img src=images/NN_Layers.png>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Is it possible to *interpret* each representation $\\y_\\llp$ ?\n",
    "- What do the new \"synthetic features\" mean ?\n",
    "- Is there some structure among the new features ?\n",
    "    - e.g., does each feature encode a \"concept\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will briefly introduce the topic of Interpretation.\n",
    "\n",
    "A deeper dive will be the subject of a later lecture.\n",
    "\n",
    "Our goal, for the moment, is to motivate Autoencoders.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpretation: Examine the weights\n",
    "\n",
    "Perhaps the most obvious may to obtain insight into the working of a Neural Network is to examine the weights.\n",
    "- When the weights are used in a dot product\n",
    "- They can be interpreted as \"patterns\" that a layer is trying to match\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The linear models of Classical Machine Learning  motivate this idea.\n",
    "\n",
    "Linear Regression\n",
    "- $\\hat{\\y} = \\Theta^T \\cdot \\x\n",
    "$\n",
    "- Prediction $\\hat{\\y}$, given features $\\x$, is linear in parameters $\\Theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Logistic Regression\n",
    "- $\n",
    "\\hat{\\mathbf{s}} = \\Theta^T \\cdot \\x\n",
    "$\n",
    "- Score $\\hat{\\mathbf{s}}$, which is turned into a probability via the sigmoid function $\\sigma$\n",
    "$$\\hat{\\mathbf{p}} = \\sigma(\\hat{\\mathbf{s}})$$\n",
    "is linear in $\\Theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's examine the role of $\\Theta_j$ in the dot product.\n",
    "\n",
    "Consider one *numeric* feature $\\x^\\ip_j$ for example $i$.\n",
    "\n",
    "- A unit increase in $\\x^\\ip_j$\n",
    "- Holding constant the values for all other features,\n",
    "- Increases $(\\Theta^T \\cdot \\x^\\ip)$ by $\\Theta_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So $\\Theta_j$ may be interpreted as the sensitivity of the dot product to a unit change in feature $j$\n",
    "$$\n",
    "\\Theta_j = \\frac{\\partial } {\\partial \\x_j} (\\Theta^T \\cdot \\x)\n",
    "$$\n",
    "\n",
    "That is: how much does the prediction or score depend on the value of the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suppose instead that $\\x_j$ corresponds to the binary feature (indicator/dummy variable)\n",
    "- $\\text{Is } c_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then the  dot product formula indicates that\n",
    "- $\\Theta_j$ is the *increment* to $(\\Theta^T \\cdot \\x)$ \n",
    "- Arising from $\\x^\\ip_j = 1$\n",
    "- Compared to $\\x^\\ip_j = 0$\n",
    "\n",
    "That is: how much the presence of feature $\\x_j$ increases the prediction or score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This idea is even more appealing when the original input $\\x^\\ip$ is an image.\n",
    "- We may be able to relate weights to recognizable sub-images of the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In Convolutional Layers, there is some evidence that\n",
    "- The first layer recognizes features (matches patterns) for *primitive* concepts\n",
    "- The second layer recognizes features that are *combinations* of primitive concepts (layer 1 concepts)\n",
    "- The $\\ll$ recognizes features that are *combinations* of layer $(\\ll-1)$ concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<div>\n",
    "    <center><strong>Features by layer</strong></center>\n",
    "    <br>\n",
    "     <!-- edX: Original: <img src=\"images/Layer_features.png\"> replace by EdX created image -->\n",
    "    <img src=\"images/ThreeLayers_W8_L2_Sl21.png\" width=20%>\n",
    "    </div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Although simple, it may be naive to hope that this technique will provide insight into multi-layer Neural Networks\n",
    "- The layers $1 \\le \\ll \\le (L-1)$ preceding the head Regression/Classification layer $L$\n",
    "- Are *transforming* input $\\x$ into synthetic features $\\y_{(L-1)}$\n",
    "- That are extremely useful for prediction\n",
    "- But which may no longer be interpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example\n",
    "- Do we recognize the digit \"0\"\n",
    "- Because of interpretable features like the doughnut shape\n",
    "- Or because of the *ratio* of dark to light pixels ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will make further attempts at interpretability that work\n",
    "- *Not* by interpreting the weights \n",
    "- Instead: by finding groups of inputs\n",
    "- And relating them to synthetic features in some layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpretation: Clustering of examples\n",
    "\n",
    "One way to try to interpret $\\y_\\llp$ is relative to a dataset $\\langle \\X, \\y \\rangle = \\{ \\x^\\ip, \\y^\\ip | 1 \\le i \\le m \\}$\n",
    "\n",
    "By passing each example $\\x^\\ip$ through the layers to obtain $\\y^\\ip_\\llp$\n",
    "- We create a mapping from examples to layer $\\ll$ representations\n",
    "$$\n",
    "\\langle \\X, \\y_\\llp \\rangle = \\{ \\x^\\ip, \\y^\\ip_\\llp \\; | \\; 1 \\le i \\le m \\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Mapping inputs to layer l representations</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Representation_1.png\"</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's create a scatter plot of each example's representation $\\y^\\ip_\\llp$ \n",
    "- In $n_\\llp$-dimensional space\n",
    "- Labeling each point \n",
    "- With the target $\\y^\\ip$\n",
    "- Or with a set of input attributes, e.g., $(\\x^\\ip_j, \\x^\\ip_{j'})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Perhaps clusters of examples will appear.\n",
    "\n",
    "If all points in the cluster have the same label\n",
    "- We might be able to identify the representation with a target or set of input features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is an example of the representation of the MNIST digits in an intermediate layer of a particular network\n",
    "- The output of the Encoder half of an Autoencoder\n",
    "- Which we will study in a subsequent lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <center>MNIST clustering produced by a VAE</center>\n",
    "    <br>\n",
    "<img src=images/VAE_plot_test-in_latent.png width=800>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Each point is an example $\\x^\\ip$\n",
    "- With coordinates chosen from two of the synthetic features in $\\y_\\llp$\n",
    "- The color corresponds to the label $\\y^\\ip$ (i.e., the digit that is represented by the image)\n",
    "\n",
    "You can see that some digits form tight clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By understanding\n",
    "- The commonality of examples within a cluster\n",
    "- How the digit label's vary as a synthetic feature varies\n",
    "\n",
    "we might be able to infer meaning of the synthetic features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The first two synthetic features in $\\y_\\llp$ of MNIST may correspond to properties of those digits\n",
    "- digits with \"tops\"\n",
    "- digits with \"curves\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Note**\n",
    "\n",
    "This is not too different from trying to interpret Principal Components. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpretation: Examining the latent space\n",
    "\n",
    "Suppose we could *invert* the representation $\\y_\\llp$ to obtain a value $\\x$ that lies in the input domain.\n",
    "\n",
    "Then \n",
    "- By perturbing individual synthetic features $\\y_{\\llp,j}$ in a given representation\n",
    "    - Perturb $\\y_\\llp$ to obtain $\\y'_\\llp$\n",
    "- And examining the effect on the inverted value $\\x'$\n",
    "- We might be able to assign meaning to the layer $\\ll$ feature $\\y_{\\llp,j}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note that the inverted value $\\x'$ **is not necessarily** (and probably not) a value in training set $\\X$ !\n",
    "- It is merely a value obtained by the mathematical inversion of a function\n",
    "- Especially since the perturbed $\\y'$ may not be the mapping of any example $\\x^\\ip \\in \\X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Invert layer l representation</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Representation_2.png\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here are the inverted images obtained by perturbing two synthetic features in $\\y_\\llp$\n",
    "- Horizontal axis perturbs one feature\n",
    "- Vertical axis perturbs a second feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<div>\n",
    "    <center>MNIST clustering produced by a VAE</center>\n",
    "    <br>\n",
    "<img src=images/VAE_examine_latent.png>\n",
    "    </div>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some observations (with possible interpretation)\n",
    "- Does the  synthetic feature on the horizontal axis control slant ?\n",
    "    - Examine 0's along bottom row\n",
    "- Does the synthetic feature on the vertical axis control \"curviness\" ?\n",
    "    - Examine the 2's column at the right edge, from bottom to top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There is *no reason to expect* that the inversion of an arbitrary representation\n",
    "*looks like* a digit but it does !\n",
    "\n",
    "Perhaps\n",
    "- The mapping from inputs to representations is such that similar inputs have very similar representations\n",
    "- Or we impose some constraints on the inversion to force the inverted value to look like a digit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In order for this method to work, we must be able to *invert* $\\y_\\llp$.\n",
    "\n",
    "We will show how to do this in a later lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deja vu: have we seen this before ?\n",
    "\n",
    "These two methods of interpretation have been encountered in an earlier lecture\n",
    "- mapping original features $\\x^\\ip$ to synthetic features $\\tilde{\\x}^\\ip$\n",
    "- inverting synthetic feature $\\tilde{\\x}^\\ip$ to obtain original feature $\\x^\\ip$\n",
    "\n",
    "Principal Component Analysis (PCA) !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "PCA is an Unsupervised Learning task that can be used for\n",
    "- dimensionality reduction\n",
    "- clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The key to it's intepretability was the simplicity of transforming and inverting\n",
    "\n",
    "$$\n",
    "\\begin{array}[llll]\\\\\n",
    "\\X & = & U \\Sigma V^T & \\text{SVD decomposition of } \\X\\\\\n",
    "\\tilde\\X & = & \\X V  & \\text{transformation to synthetic features}\\\\\n",
    "\\X & = & \\tilde\\X V^T  & \\text{inverse transformation to original features}\\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The transformation $V$ via matrix multiplication is *linear*.\n",
    "\n",
    "We will explore *non-linear, invertible* transformations during our study of Autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Neural Networks have the reputation of being magical but opaque.\n",
    "\n",
    "We hope this brief introduction to interpretation provides some hope that we can understand their inner workings.\n",
    "\n",
    "A separate lecture will explore this topic in greater depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
